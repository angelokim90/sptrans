{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ad67b6-6a6e-4965-930d-2c1a4c87f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros: 421212923\n",
      "Tempo de leitura: 5.72 segundos\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum,count,round , lit,when,substring,avg,countDistinct,floor,max,min\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import locale\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Pré-processamento\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder as OneHotEncoderSpark, VectorAssembler, MinMaxScaler as MinMaxScalerSpark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Clusterização Hierárquica\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.decomposition import PCA\n",
    "# Clusterização K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "# Métrica de qualidade de clusters\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "caminho =r'D:/base_ans_parquet/'\n",
    "\n",
    "anos_filtrar = [\"2023\", \"2024\", \"2025\"]\n",
    "\n",
    "arquivos_parquet = [\n",
    "    os.path.join(caminho, f)\n",
    "    for f in os.listdir(caminho)\n",
    "    if f.endswith(\".parquet\") and any(ano in f for ano in anos_filtrar)\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LeituraParquet\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "inicio = time.time()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\")\n",
    "\n",
    "df = spark.read.parquet(*arquivos_parquet)\n",
    "total_registros = df.count()  # Força leitura e conta registros\n",
    "fim = time.time()\n",
    "\n",
    "print(f\"Total de registros: {total_registros}\")\n",
    "print(f\"Tempo de leitura: {fim - inicio:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a2cb9c-9ca8-411e-847f-5304c5be89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRAR DADOS\n",
    "df_soma0 = df.agg(sum(\"QT_BENEFICIARIO_ATIVO\").alias(\"soma_total\"))\n",
    "#df_soma0.show()\n",
    "#FILTRAR APENAS USUARIOS DE PLANO DE SAUDE, EXCLUIR ODONTOLOGICO \n",
    "df_filtrado = df.filter(\n",
    "    (col(\"COBERTURA_ASSIST_PLAN\") == \"Médico-hospitalar\")     \n",
    ")\n",
    "df_soma = df_filtrado.agg(sum(\"QT_BENEFICIARIO_ATIVO\").alias(\"soma_total\"))\n",
    "#df_soma.show()\n",
    "\n",
    "\n",
    "#REMOVER USUARIOS SEM FAIXA ETARIA, SEM VINCULO\n",
    "df_filtrado2345 = df_filtrado.filter(\n",
    "    (col(\"DE_FAIXA_ETARIA\") != \"Informada Incorr\") &\n",
    "    (col(\"TIPO_VINCULO\") != \"Não Identificado\") &\n",
    "    (col(\"SG_UF\") != \"XX\") &\n",
    "    (col(\"DE_CONTRATACAO_PLANO\") != \"Não Identificado\")\n",
    ")\n",
    "df_soma2 = df_filtrado2345.agg(sum(\"QT_BENEFICIARIO_ATIVO\").alias(\"soma_total\"))\n",
    "#df_soma2.show()\n",
    "\n",
    "df_filtrado6 = df_filtrado2345.filter(\n",
    "    col(\"ID_CMPT_MOVEL\").isin(\"2025-05\")\n",
    ")\n",
    "\n",
    "\n",
    "colunas_ok = [\n",
    "    \"ID_CMPT_MOVEL\", \"NM_RAZAO_SOCIAL\", \"SG_UF\",\n",
    "    \"TP_SEXO\", \"DE_FAIXA_ETARIA\", \"DE_FAIXA_ETARIA_REAJ\",\n",
    "    \"DE_CONTRATACAO_PLANO\", \"TIPO_VINCULO\",\n",
    "    \"QT_BENEFICIARIO_ATIVO\", \"QT_BENEFICIARIO_ADERIDO\", \"QT_BENEFICIARIO_CANCELADO\"\n",
    "]\n",
    "\n",
    "# Colunas numéricas que vamos somar\n",
    "colunas_numericas = [\n",
    "    \"QT_BENEFICIARIO_ATIVO\", \"QT_BENEFICIARIO_ADERIDO\", \"QT_BENEFICIARIO_CANCELADO\"\n",
    "]\n",
    "\n",
    "colunas_grupo = list(set(colunas_ok) - set(colunas_numericas))\n",
    "\n",
    "df_filtrado6a = df_filtrado6.groupBy(colunas_grupo).agg(\n",
    "    *[sum(col).alias(col) for col in colunas_numericas]\n",
    ")\n",
    "\n",
    "# Exibe o resultado\n",
    "#df_filtrado6a.show(truncate=False)\n",
    "\n",
    "df_somagroupby = df_filtrado6a.groupBy(\"DE_FAIXA_ETARIA_REAJ\", \"TIPO_VINCULO\").agg(sum(\"QT_BENEFICIARIO_ATIVO\").alias(\"soma_valor\"))\n",
    "\n",
    "df_filtrado7 = df_filtrado6a.filter(\n",
    "    (col(\"ID_CMPT_MOVEL\")==\"2025-05\") #&\n",
    "    #(col(\"NM_RAZAO_SOCIAL\")==\"BRADESCO SAÚDE S.A.\" ) #&\n",
    "    #(col(\"SG_UF\").isin(\"PR\"))\n",
    "    \n",
    ")\n",
    "\n",
    "#df_filtrado7.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f6a537-05d1-4378-967c-ca75cf423e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{452046}\n"
     ]
    }
   ],
   "source": [
    "qtde=df_filtrado7.count()\n",
    "print ({qtde})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e344bb3-19f2-4b6b-8566-e53b4eda9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Selecionar colunas numéricas e categóricas\n",
    "col_numericas = [\n",
    "    \"QT_BENEFICIARIO_ATIVO\",\n",
    "    \"QT_BENEFICIARIO_ADERIDO\",\n",
    "    \"QT_BENEFICIARIO_CANCELADO\"\n",
    "]\n",
    "col_categoricas = [\n",
    "    \"TIPO_VINCULO\",\n",
    "    \"DE_FAIXA_ETARIA\",\n",
    "    \"TP_SEXO\",\n",
    "    \"DE_CONTRATACAO_PLANO\"\n",
    "]\n",
    "\n",
    "# 5. StringIndexer + OneHotEncoder para cada coluna categórica\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\") for col in col_categoricas]\n",
    "\n",
    "# OneHotEncoder para múltiplas colunas (PySpark 4.0)\n",
    "encoder = OneHotEncoderSpark(\n",
    "    inputCols=[f\"{col}_idx\" for col in col_categoricas],\n",
    "    outputCols=[f\"{col}_vec\" for col in col_categoricas],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "# Pipeline de transformação\n",
    "pipeline = Pipeline(stages=indexers + [encoder])\n",
    "df_encoded = pipeline.fit(df_filtrado7).transform(df_filtrado7)\n",
    "\n",
    "# Junta tudo num vetor de features\n",
    "input_features = col_numericas + [f\"{col}_vec\" for col in col_categoricas]\n",
    "assembler = VectorAssembler(inputCols=input_features, outputCol=\"features_raw\")\n",
    "df_vector = assembler.transform(df_encoded)\n",
    "\n",
    "# Escalona com MinMaxScaler\n",
    "scaler = MinMaxScalerSpark(inputCol=\"features_raw\", outputCol=\"features_scaled\")\n",
    "df_scaled = scaler.fit(df_vector).transform(df_vector)\n",
    "\n",
    "# Coleta os dados como vetores NumPy para clusterização fora do Spark\n",
    "X = df_scaled.select(\"features_scaled\").rdd.map(lambda row: row[\"features_scaled\"].toArray()).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f55fe1-2202-46c6-a5e1-3645b963577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variância explicada total: 81.59%\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# 2. Verifica quanta variância foi preservada\n",
    "print(f\"Variância explicada total: {np.sum(pca.explained_variance_ratio_):.2%}\")\n",
    "\n",
    "\n",
    "ks = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km_labels = km.fit_predict(X_pca)\n",
    "    inertias.append(km.inertia_)                        # atributo inertia_ do KMeans\n",
    "    silhouettes.append(silhouette_score(X, km_labels))  # silhueta para cada k\n",
    "\n",
    "# 4.2. Plot do Método do Cotovelo (Inércia vs k)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(ks, inertias, 'o-', color='C0')\n",
    "plt.title('Elbow Method (K-Means)')\n",
    "plt.xlabel('Número de clusters k')\n",
    "plt.ylabel('Inércia (Soma de distâncias quadráticas)')\n",
    "plt.show()\n",
    "\n",
    "# 4.3. Plot dos Scores de Silhueta (Silhueta vs k)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(ks, silhouettes, 'o-', color='C1')\n",
    "plt.title('Silhouette Score (K-Means)')\n",
    "plt.xlabel('Número de clusters k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "\n",
    "# 4.4. Seleção automática do k que maximiza o Silhouette Score\n",
    "k_opt = ks[np.argmax(silhouettes)]\n",
    "print(f\"k ótimo pelo Silhouette Score: {k_opt}\")\n",
    "\n",
    "# 4.5. Ajuste final do modelo K-Means com o k ótimo\n",
    "km_opt = KMeans(n_clusters=k_opt, random_state=42)\n",
    "labels_km = km_opt.fit_predict(X)\n",
    "\n",
    "# 4.6. Métricas para o modelo final\n",
    "print(f\"K-Means k={k_opt} → Inércia: {km_opt.inertia_:.3f}, \"\n",
    "      f\"Silhueta: {silhouette_score(X, labels_km):.3f}\\n\")\n",
    "\n",
    "\n",
    "# 4.7. Visualização dos clusters em 2D (duas primeiras features escalonadas)\n",
    "plt.figure(figsize=(6, 6))\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=labels_km, cmap='tab10', s=10)\n",
    "X = np.array(X)\n",
    "plt.title(f'Clusters K-Means (k={k_opt})')\n",
    "plt.xlabel('Feature 1 (escalonada)')\n",
    "plt.ylabel('Feature 2 (escalonada)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03567f-0579-41ef-9215-e85f13886e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017884b-36dc-436f-8b83-01b6c4e6e589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f47ad-4381-4997-abc6-e127bce56afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
